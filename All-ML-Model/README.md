# ğŸ¤– Multi-Model Comparison â€” Breast Cancer Diagnosis

This project benchmarks a variety of machine learning classifiers on the **Breast Cancer Diagnostic** dataset to predict whether tumors are **benign** or **malignant**. The notebook evaluates traditional models, ensemble methods, and gradient boosting algorithms side by side.

---

## âœ¨ Models Compared
- ğŸ“ˆ Logistic Regression  
- ğŸŒ³ Decision Tree  
- âš™ï¸ Support Vector Machine (SVC â€“ Linear Kernel)  
- ğŸŒ² Random Forest  
- ğŸ“ K-Nearest Neighbors (KNN)  
- ğŸ“Š Naive Bayes  
- ğŸš€ Gradient Boosting  
- ğŸ” AdaBoost  
- ğŸ”¥ XGBoost  
- ğŸ’¡ LightGBM  
- ğŸ± CatBoost  

---

## ğŸš€ Getting Started
Open the notebook in **Google Colab** to view code, train models, and visualize results interactively:

ğŸ”— [**Open in Google Colab**](https://colab.research.google.com/drive/19b1ywoWC5pC6GkMGvdglDzaMCbjo9vkv?usp=sharing)



---

## ğŸ“Š Results
Each model was evaluated using **Accuracy Score** on the held-out test set.  

### ğŸ” Accuracy Comparison

- **Random Forest** achieved the highest accuracy among all tested models.  
- **Ensemble methods (XGBoost, LightGBM, CatBoost)** performed consistently well.  
- **KNN** showed slightly lower accuracy compared to tree-based and boosting methods.  

---

## ğŸ› ï¸ Tech Stack
- Python ğŸ  
- NumPy Â· Pandas Â· Matplotlib Â· Seaborn  
- Scikit-Learn (core ML algorithms + metrics)  
- XGBoost Â· LightGBM Â· CatBoost  

---



