# 🤖 Multi-Model Comparison — Breast Cancer Diagnosis

This project benchmarks a variety of machine learning classifiers on the **Breast Cancer Diagnostic** dataset to predict whether tumors are **benign** or **malignant**. The notebook evaluates traditional models, ensemble methods, and gradient boosting algorithms side by side.

---

## ✨ Models Compared
- 📈 Logistic Regression  
- 🌳 Decision Tree  
- ⚙️ Support Vector Machine (SVC – Linear Kernel)  
- 🌲 Random Forest  
- 📍 K-Nearest Neighbors (KNN)  
- 📊 Naive Bayes  
- 🚀 Gradient Boosting  
- 🔁 AdaBoost  
- 🔥 XGBoost  
- 💡 LightGBM  
- 🐱 CatBoost  

---

## 🚀 Getting Started
Open the notebook in **Google Colab** to view code, train models, and visualize results interactively:

🔗 [**Open in Google Colab**](https://colab.research.google.com/drive/19b1ywoWC5pC6GkMGvdglDzaMCbjo9vkv?usp=sharing)



---

## 📊 Results
Each model was evaluated using **Accuracy Score** on the held-out test set.  

### 🔎 Accuracy Comparison

- **Random Forest** achieved the highest accuracy among all tested models.  
- **Ensemble methods (XGBoost, LightGBM, CatBoost)** performed consistently well.  
- **KNN** showed slightly lower accuracy compared to tree-based and boosting methods.  

---

## 🛠️ Tech Stack
- Python 🐍  
- NumPy · Pandas · Matplotlib · Seaborn  
- Scikit-Learn (core ML algorithms + metrics)  
- XGBoost · LightGBM · CatBoost  

---



